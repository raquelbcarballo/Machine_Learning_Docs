{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis process\n",
    "\n",
    "The data analysis process involves several steps that are typically followed to extract insights or meaning from a given dataset.\n",
    "\n",
    "1. **Establish an objective**: This step involves clearly defining the problem you want to solve or the goal you want to achieve using machine learning. This objective should be specific, measurable, achievable, relevant, and time-bound.\n",
    "\n",
    "2. **Establish metrics**: Once you have established an objective, the next step is to determine the metrics or criteria for evaluating the performance of your model. These metrics should align with your objective and be easy to measure.\n",
    "\n",
    "3. **Obtaining the domain knowledge**: It is important to have a good understanding of the domain or industry you are working in. This can help you identify relevant features and variables to include in your model.\n",
    "\n",
    "4. **Data collection**: In this step, you gather data relevant to the objective of your machine learning model. Data can be collected from various sources such as databases, APIs, or public data sources.\n",
    "\n",
    "5. **Exploratory analysis = EDA (Exploratory Data Analysis)**: In this step, you perform EDA to gain a better understanding of the data you collected. This helps identify patterns, correlations, and potential issues that may affect the model's performance.\n",
    "\n",
    "6. **Processing of characteristics**: This step involves pre-processing the data to prepare it for modeling. This may involve data cleaning, normalization, and transformation.\n",
    "\n",
    "7. **Character engineering**: Feature engineering involves selecting and transforming the variables that will be used as inputs to your model. This step is crucial as the quality of the features you select can have a significant impact on the model's performance.\n",
    "\n",
    "8. **Selection of an algorithm**: There are various algorithms available for building machine learning models. This step involves selecting an appropriate algorithm that can achieve your objective and work with the available data.\n",
    "\n",
    "9. **Optimisation of hyperparameters**: Hyperparameters are parameters of the machine learning algorithm that are not learned from the data but must be set before training. This step involves finding the best hyperparameters to maximize model performance.\n",
    "\n",
    "10. **Training**: Once you have selected an algorithm and optimized its hyperparameters, the next step is to train the model on the data you collected.\n",
    "\n",
    "11. **Evaluation of the model (Return to the 6 if is necessary)**: In this step, you evaluate the performance of your model using the metrics you established earlier. If the model's performance is not satisfactory, you may need to go back to previous steps and make adjustments.\n",
    "\n",
    "12. **Model assembly**: Once you are satisfied with the model's performance, you can assemble it and deploy it for use in production. This may involve creating a user interface or integrating the model into an existing system."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python science stack, also known as the Python scientific ecosystem, is a collection of open-source Python libraries and tools that are used for scientific computing and data analysis. These libraries and tools enable researchers, data scientists, and analysts to perform complex calculations, data visualization, and machine learning tasks with ease. The main components of the Python science stack include:\n",
    "\n",
    "* [NumPy](./Python_Numpy.ipynb): NumPy is a fundamental library for numerical computing in Python. It provides powerful array operations and linear algebra routines, which are used extensively in scientific and data analysis applications.\n",
    "\n",
    "* SciPy: SciPy is a library for scientific computing that builds on top of NumPy. It provides additional functionality for optimization, interpolation, signal processing, and more.\n",
    "\n",
    "* [Pandas](./Python_Pandas.ipynb): Pandas is a library for data manipulation and analysis. It provides tools for reading and writing data in various formats, cleaning and transforming data, and performing aggregations and statistical analysis. Is built on NumPy.\n",
    "\n",
    "* [Matplotlib](./Python_Matplotlib.ipynb): Matplotlib is a library for creating visualizations in Python. It provides a wide range of customizable plots, charts, and graphs, which can be used to display data in a meaningful way.\n",
    "\n",
    "* [Seaborn](./Python_Seaborn.ipynb): Seaborn is a library for data visualization built on top of Matplotlib. It provides additional functionality for creating more complex and aesthetically pleasing visualizations. Is built on matplotlib.\n",
    "\n",
    "* Scikit-learn: Scikit-learn is a library for machine learning in Python. It provides a wide range of algorithms for classification, regression, clustering, and more.\n",
    "\n",
    "* TensorFlow: TensorFlow is an open-source platform for building and deploying machine learning models. It provides a low-level API for building custom models, as well as high-level APIs for building models quickly and easily.\n",
    "\n",
    "* Keras: Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow. It provides a simplified interface for building neural networks, making it easier to build complex models with fewer lines of code.\n",
    "\n",
    "These libraries are widely used in the data science and machine learning community, and their popularity has made Python one of the leading languages for scientific computing and data analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "develop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
